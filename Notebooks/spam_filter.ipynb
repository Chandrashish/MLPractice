{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "pd.read_csv('spam.csv') # raises unicode decode error\n",
    "\n",
    "pd.read_csv('spam.csv', encoding='Latin-1') # works \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Windows-1252\n"
     ]
    }
   ],
   "source": [
    "# when encoding is unknown\n",
    "import chardet \n",
    "with open(\"../Data/sms_spam/spam.csv\", 'rb') as f:\n",
    "    result = chardet.detect(f.read())  # or readline if the file is large\n",
    "\n",
    "print(result['encoding'])\n",
    "df_raw = pd.read_csv('../Data/sms_spam/spam.csv', encoding=result['encoding'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_raw[['v1', 'v2']].rename(columns={'v1' : 'label', 'v2' : 'sms'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                                sms\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5572</td>\n",
       "      <td>5572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>5169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4825</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                     sms\n",
       "count   5572                    5572\n",
       "unique     2                    5169\n",
       "top      ham  Sorry, I'll call later\n",
       "freq    4825                      30"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset='sms', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5169</td>\n",
       "      <td>5169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>5169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry man, accidentally left my phone on silen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4516</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                                                sms\n",
       "count   5169                                               5169\n",
       "unique     2                                               5169\n",
       "top      ham  Sorry man, accidentally left my phone on silen...\n",
       "freq    4516                                                  1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>4516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label   sms\n",
       "0   ham  4516\n",
       "1  spam   653"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('label').count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['len'] = df['sms'].map(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>4516</td>\n",
       "      <td>70.459256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>653</td>\n",
       "      <td>137.891271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label   sms         len\n",
       "0   ham  4516   70.459256\n",
       "1  spam   653  137.891271"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('label').agg({'sms': 'count', 'len' : 'mean'}).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separate training data and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X is (5169,)\n",
      "Shape of X_train is (3876,) and shape of y_train is (3876,)\n",
      "Shape of X_test is (1293,) and shape of y_test is (1293,)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Train-test split: Do not touch the test data until the time of final evaluation.\n",
    "        Which stage of the pipeline do we reserve the test data ?\n",
    "            - after obtaining raw data but before cleaning it \n",
    "            - after cleaning but before exploring\n",
    "            - after exploring but before featurizing/training\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df['sms']\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "print(\"Shape of X is {}\".format(X.shape))\n",
    "print(\"Shape of X_train is {} and shape of y_train is {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Shape of X_test is {} and shape of y_test is {}\".format(X_test.shape, y_test.shape))\n",
    "\n",
    "train_corpus = list(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a featurizer from training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features = 5000\n",
      "Number of omitted words = 2395\n",
      "Shape of X_train_text_features is (3876, 5000)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Featurizer: Train the featurizer on train data.\n",
    "\"\"\"\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "vectorizer.fit(train_corpus)\n",
    "\n",
    "print(\"Number of features = {}\".format(len(vectorizer.vocabulary_)))\n",
    "print(\"Number of omitted words = {}\".format(len(vectorizer.stop_words_)))\n",
    "\n",
    "X_train_text_features = vectorizer.transform(list(X_train))\n",
    "print(\"Shape of X_train_text_features is {}\".format(X_train_text_features.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Adding a new feature\n",
    "        Do we need to do the train-test split again ?\n",
    "        >> Yes, if you do not have the new feature in your previous dataframe.\n",
    "        Otherwise you have to join the corresponding indices.\n",
    "        \n",
    "        Do we need to normalize the new feature being added ?\n",
    "        >> It depends on the model.\n",
    "            - perhaps decision tree models would not require normalization\n",
    "            - linear models would require normalization\n",
    "\"\"\"\n",
    "\n",
    "df['len'] = df['sms'].map(lambda x: len(x))\n",
    "\n",
    "X = df[['sms', 'len']]\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, y, random_state=42)\n",
    "\n",
    "train_corpus = list(X_train['sms'])\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "vectorizer.fit(train_corpus)\n",
    "\n",
    "from scipy import sparse\n",
    "def get_features(X):\n",
    "    X_text_features = vectorizer.transform(list(X['sms']))\n",
    "    X_len_features = sparse.csr_matrix(X['len']).T\n",
    "    X_features = sparse.hstack([X_text_features, X_len_features])\n",
    "    return X_features\n",
    "\n",
    "X_train_features = get_features(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=42, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Training a classifier: Train a Logistic Regression classifier\n",
    "        The classifier uses default setting: L2 regularization is used\n",
    "        Random state is fixed to 42 in order to be able to repeat the experiment to obtain the same results\n",
    "\"\"\"\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(random_state=42)\n",
    "\n",
    "model.fit(X_train_features, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fraction of correctly classified samples is 0.9760061919504643\n",
      "The number of correctly classified samples is 3783\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred ham</th>\n",
       "      <th>pred spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true spam</th>\n",
       "      <td>3399</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true ham</th>\n",
       "      <td>10</td>\n",
       "      <td>384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pred ham  pred spam\n",
       "true spam      3399         83\n",
       "true ham         10        384"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Evaluation on training data: This does not mean anything  \n",
    "        Do not take the evaluate on the same data that you trained on very seriously\n",
    "\"\"\"\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "y_train_predicted = model.predict(X_train_features)\n",
    "\n",
    "print(\"The fraction of correctly classified samples is {}\".format(accuracy_score(y_train, y_train_predicted)))\n",
    "print(\"The number of correctly classified samples is {}\".format(accuracy_score(y_train, \n",
    "                                                                               y_train_predicted, normalize=False)))\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_train_predicted, y_train), \n",
    "             index={'true ham', 'true spam'}, \n",
    "             columns={'pred ham', 'pred spam'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95618557 0.95489691 0.97290323 0.96258065 0.96640827]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Evaluation within training data: k-fold cross validation\n",
    "        - randomly partition the training data into k parts\n",
    "        - train on k-1 parts and evaluate on the remaining part\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "lr_model = LogisticRegression()\n",
    "cv_scores = cross_val_score(lr_model, X=X_train_features, y=y_train, cv=5, n_jobs=4)\n",
    "print(cv_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.linear_model import LogisticRegressionCV\\ncv_model = LogisticRegressionCV(cv=5, random_state=42)\\ncv_model.fit(X_train_features, y_train)\\ncv_model.scores_\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "The LogisticRegressionCV classifier has inbuilt cross validation\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "cv_model = LogisticRegressionCV(cv=5, random_state=42)\n",
    "cv_model.fit(X_train_features, y_train)\n",
    "cv_model.scores_\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final evaluation on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fraction of correctly classified samples is 0.9737045630317092\n",
      "The number of correctly classified samples is 1259\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred ham</th>\n",
       "      <th>pred spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true spam</th>\n",
       "      <td>1106</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true ham</th>\n",
       "      <td>1</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pred ham  pred spam\n",
       "true spam      1106         33\n",
       "true ham          1        153"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Evaluation on test data: This score is important\n",
    "\"\"\"\n",
    "X_test_features = get_features(X_test)\n",
    "y_test_predicted = model.predict(X_test_features)\n",
    "\n",
    "print(\"The fraction of correctly classified samples is {}\".format(accuracy_score(y_test, y_test_predicted)))\n",
    "print(\"The number of correctly classified samples is {}\".format(accuracy_score(y_test, y_test_predicted, normalize=False)))\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_test_predicted, y_test), \n",
    "             index={'true ham', 'true spam'}, \n",
    "             columns={'pred ham', 'pred spam'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serializing and saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['featurizer_joblib_2019_January_06']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "from datetime import date\n",
    "\n",
    "\"\"\"\n",
    "    Versioning: It is often useful to save the model with a version number.\n",
    "        One way to do it is to attach current date/time to the filename saved\n",
    "\"\"\"\n",
    "version = date.today().strftime(\"%Y_%B_%d\")\n",
    "joblib.dump(vectorizer, 'vectorizer_joblib_{}'.format(version))\n",
    "joblib.dump(model, 'lr_model_joblib_{}'.format(version))\n",
    "\n",
    "\"\"\"\n",
    "    How to serialize a function ? \n",
    "        Would the following work ?\n",
    "\"\"\"\n",
    "joblib.dump(get_features, 'featurizer_joblib_{}'.format(version))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fraction of correctly classified samples is 0.9737045630317092\n",
      "The number of correctly classified samples is 1259\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred ham</th>\n",
       "      <th>pred spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true spam</th>\n",
       "      <td>1106</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true ham</th>\n",
       "      <td>1</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pred ham  pred spam\n",
       "true spam      1106         33\n",
       "true ham          1        153"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reloaded_model = joblib.load('../Models/lr_model_joblib_2018_December_24')\n",
    "y_test_predicted = reloaded_model.predict(X_test_features)\n",
    "\n",
    "print(\"The fraction of correctly classified samples is {}\".format(accuracy_score(y_test, y_test_predicted)))\n",
    "print(\"The number of correctly classified samples is {}\".format(accuracy_score(y_test, y_test_predicted, normalize=False)))\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_test_predicted, y_test), \n",
    "             index={'true ham', 'true spam'}, \n",
    "             columns={'pred ham', 'pred spam'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham'], dtype=object)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reloaded_featurizer = joblib.load('../Models/featurizer_joblib_2018_December_24')\n",
    "reloaded_vectorizer = joblib.load('../Models/vectorizer_joblib_2018_December_24')\n",
    "reloaded_model = joblib.load('../Models/lr_model_joblib_2018_December_24')\n",
    "\n",
    "text = \"I am not spam.\"\n",
    "\n",
    "X_text = pd.DataFrame({'sms': [text], 'len': [len(text)]})\n",
    "reloaded_model.predict(reloaded_featurizer(X_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 20 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "call       3.946334\n",
       "txt        3.356191\n",
       "text       2.795574\n",
       "free       2.792163\n",
       "mobile     2.465806\n",
       "claim      2.306686\n",
       "reply      2.279622\n",
       "service    2.265740\n",
       "stop       2.201091\n",
       "150p       2.188507\n",
       "www        2.084460\n",
       "uk         2.027968\n",
       "your       1.877783\n",
       "50         1.834914\n",
       "now        1.810069\n",
       "win        1.770189\n",
       "won        1.746124\n",
       "prize      1.739970\n",
       "or         1.666726\n",
       "message    1.654107\n",
       "dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series (\n",
    "    reloaded_model.coef_.T.ravel(),\n",
    "    index=vectorizer.get_feature_names() + ['LEN']\n",
    ").sort_values(ascending=False)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "- How to handle class imbalance?\n",
    "https://elitedatascience.com/imbalanced-classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series\n",
    "    final_clf.coef_.T.ravel(),\n",
    "    index=vectorizer.get_feature_names()\n",
    ").sort_values(ascending=False)[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and evaluating multiple models\n",
    "\n",
    "https://www.kaggle.com/muzzzdy/sms-spam-detection-with-various-classifiers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raghav/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9625949227856792\n",
      "0.9563970468562157\n",
      "0.9687848164790338\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Observing cross validation scores of several models    \n",
    "\"\"\"\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "models = defaultdict()\n",
    "\n",
    "logistic_regression = LogisticRegression()\n",
    "models['logistic_regression'] = logistic_regression\n",
    "\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "models['decision_tree'] = decision_tree\n",
    "\n",
    "random_forest = RandomForestClassifier()\n",
    "models['random_forest'] = random_forest\n",
    "\n",
    "\n",
    "for key, model in models.items():\n",
    "    cv_score = cross_val_score(model, X_train_features, y_train, cv=5, n_jobs=4).mean()\n",
    "    print(cv_score)\n",
    "    models[key] = {'model': model, 'cv_score': cv_score}\n",
    "    \n",
    "df_scores = pd.DataFrame.from_dict(models, orient='index', columns=['cv_score'])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble: Voting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fraction of correctly classified samples is 0.9760247486465584\n",
      "The number of correctly classified samples is 1262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raghav/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred ham</th>\n",
       "      <th>pred spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true spam</th>\n",
       "      <td>1107</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true ham</th>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pred ham  pred spam\n",
       "true spam      1107         31\n",
       "true ham          0        155"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "voting_classifier = VotingClassifier(estimators=[('lr', logistic_regression), \n",
    "                                                 ('dt', decision_tree), \n",
    "                                                 ('rf', random_forest)])\n",
    "\n",
    "voting_classifier.fit(X_train_features, y_train)\n",
    "\n",
    "y_test_predicted = voting_classifier.predict(X_test_features)\n",
    "\n",
    "print(\"The fraction of correctly classified samples is {}\".format(accuracy_score(y_test, y_test_predicted)))\n",
    "print(\"The number of correctly classified samples is {}\".format(accuracy_score(y_test, y_test_predicted, normalize=False)))\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_test_predicted, y_test), \n",
    "             index={'true ham', 'true spam'}, \n",
    "             columns={'pred ham', 'pred spam'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression: Hyperparameter Tuning via Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raghav/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[mean: 0.89680, std: 0.00743, params: {'C': 0.25, 'class_weight': None, 'penalty': 'l1'},\n",
       " mean: 0.91022, std: 0.00563, params: {'C': 0.25, 'class_weight': None, 'penalty': 'l2'},\n",
       " mean: 0.89319, std: 0.00213, params: {'C': 0.25, 'class_weight': 'balanced', 'penalty': 'l1'},\n",
       " mean: 0.92337, std: 0.00679, params: {'C': 0.25, 'class_weight': 'balanced', 'penalty': 'l2'},\n",
       " mean: 0.93885, std: 0.00578, params: {'C': 0.5, 'class_weight': None, 'penalty': 'l1'},\n",
       " mean: 0.93808, std: 0.00412, params: {'C': 0.5, 'class_weight': None, 'penalty': 'l2'},\n",
       " mean: 0.93473, std: 0.00488, params: {'C': 0.5, 'class_weight': 'balanced', 'penalty': 'l1'},\n",
       " mean: 0.95253, std: 0.00476, params: {'C': 0.5, 'class_weight': 'balanced', 'penalty': 'l2'},\n",
       " mean: 0.95691, std: 0.00323, params: {'C': 1, 'class_weight': None, 'penalty': 'l1'},\n",
       " mean: 0.95743, std: 0.00577, params: {'C': 1, 'class_weight': None, 'penalty': 'l2'},\n",
       " mean: 0.95356, std: 0.00505, params: {'C': 1, 'class_weight': 'balanced', 'penalty': 'l1'},\n",
       " mean: 0.96723, std: 0.00369, params: {'C': 1, 'class_weight': 'balanced', 'penalty': 'l2'}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Training and evaluating a Logistic Regression model on combination of hyperparameters\n",
    "\"\"\"\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "hyper_parameters = {\n",
    "    'penalty' : ['l1', 'l2'],\n",
    "    'class_weight' : [None, 'balanced'],\n",
    "    'C': [0.25, 0.5, 1]\n",
    "}\n",
    "\n",
    "logistic_regression = LogisticRegression()\n",
    "\n",
    "grid_search_classifier = GridSearchCV(logistic_regression, hyper_parameters, cv=3)\n",
    "nb_detector = grid_search_classifier.fit(X_train_features, y_train)\n",
    "nb_detector.grid_scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree: hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean = 0.8795153840006392 std = 0.0005332502619686193\n",
      "mean = 0.9187342368238107 std = 0.004089638434043284\n",
      "mean = 0.9354971251403917 std = 0.004593070527927408\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Training a decision tree of various depth and printing cross validation scores\n",
    "\"\"\"\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "d_max = 3\n",
    "\n",
    "cv_scores = []\n",
    "for d in range(1, d_max+1):\n",
    "    model = DecisionTreeClassifier(max_depth=d)\n",
    "    scores = cross_val_score(model, X=X_train_features, y=y_train, cv=5, n_jobs=4)\n",
    "    cv_scores.append((scores.mean(), scores.std()))\n",
    "    \n",
    "for mean, std in cv_scores:\n",
    "    print(\"mean = {} std = {}\".format(mean, std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Windows-1252\n",
      "Shape of X is (5169,)\n",
      "Shape of X_train is (3876,) and shape of y_train is (3876,)\n",
      "Shape of X_test is (1293,) and shape of y_test is (1293,)\n",
      "The cross validation scores are: [0.96134021 0.95876289 0.96645161 0.95612903 0.95994832]\n",
      "The fraction of correctly classified samples is 0.9644238205723125\n",
      "The number of correctly classified samples is 1247\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred ham</th>\n",
       "      <th>pred spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>true ham</th>\n",
       "      <td>1104</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true spam</th>\n",
       "      <td>3</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           pred ham  pred spam\n",
       "true ham       1104         43\n",
       "true spam         3        143"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import chardet \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datetime import date\n",
    "\n",
    "path_to_data = \"../Data/spam.csv\"\n",
    "# when encoding is unknown\n",
    "with open(path_to_data, 'rb') as f:\n",
    "    result = chardet.detect(f.read())  # or readline if the file is large\n",
    "\n",
    "print(result['encoding'])\n",
    "df_raw = pd.read_csv(\n",
    "    path_to_data, encoding=result['encoding'])\n",
    "\n",
    "df = df_raw[['v1', 'v2']].rename(columns={'v1' : 'label', 'v2' : 'sms'})\n",
    "df.drop_duplicates(subset='sms', inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "X = df['sms']\n",
    "y = df['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "print(\"Shape of X is {}\".format(X.shape))\n",
    "print(\"Shape of X_train is {} and shape of y_train is {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Shape of X_test is {} and shape of y_test is {}\".format(X_test.shape, y_test.shape))\n",
    "\n",
    "pipeline = Pipeline([('vectorizer', TfidfVectorizer()),\n",
    "                     ('classifier', LogisticRegression())])\n",
    "\n",
    "\n",
    "print(\"The cross validation scores are: {}\".format(cross_val_score(pipeline, X=X_train, y=y_train, cv=5)))\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "version = date.today().strftime(\"%Y_%B_%d\")\n",
    "model_path = '../Models/Spam/model.joblib_{}'.format(version)\n",
    "joblib.dump(pipeline, model_path)\n",
    "\n",
    "reloaded_pipeline = joblib.load(model_path)\n",
    "\n",
    "\n",
    "y_test_predicted = reloaded_pipeline.predict(X_test)\n",
    "\n",
    "print(\"The fraction of correctly classified samples is {}\".format(accuracy_score(y_test, y_test_predicted)))\n",
    "print(\"The number of correctly classified samples is {}\".format(accuracy_score(y_test, y_test_predicted, normalize=False)))\n",
    "\n",
    "\n",
    "pd.DataFrame(confusion_matrix(y_test, y_test_predicted), # y_test comes first\n",
    "             index={'true ham', 'true spam'}, \n",
    "             columns={'pred ham', 'pred spam'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a flask-API \n",
    "# Creating a docker image of the flask-app\n",
    "# Deploying the docker image to AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.joblib_2018_December_26\n",
      "model.joblib_2018_December_29\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'model.joblib_2018_December_29'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import os \n",
    "\n",
    "filenames = []\n",
    "for root, dirs, files in os.walk(\"../Models/Spam\"):   \n",
    "    for filename in files: \n",
    "        print(filename) \n",
    "        filenames.append(filename)\n",
    "filenames.sort(key=lambda x: x.split('joblib')[-1], reverse=True)\n",
    "\n",
    "filenames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
